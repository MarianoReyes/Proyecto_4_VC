{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "!pip install numpy pandas scikit-learn tensorflow opencv-python mediapipe joblib\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "class handDetector():\n",
    "    def __init__(self, mode=False, maxHands=2, detectionCon=0.5, trackCon=0.5):\n",
    "        self.mode = mode\n",
    "        self.maxHands = maxHands\n",
    "        self.detectionCon = detectionCon\n",
    "        self.trackCon = trackCon\n",
    "\n",
    "        self.mpHands = mp.solutions.hands\n",
    "        self.hands = self.mpHands.Hands(static_image_mode=self.mode, max_num_hands=self.maxHands,\n",
    "                                        min_detection_confidence=self.detectionCon, min_tracking_confidence=self.trackCon)\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "    def findHands(self, img, draw=True):\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imgRGB)\n",
    "\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                    self.mpDraw.draw_landmarks(img, handLms,\n",
    "                                               self.mpHands.HAND_CONNECTIONS)\n",
    "        return img\n",
    "\n",
    "    def findPosition(self, img, handNo=0, draw=True):\n",
    "        lmList = []\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            myHand = self.results.multi_hand_landmarks[handNo]\n",
    "            for id, lm in enumerate(myHand.landmark):\n",
    "                h, w, c = img.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                lmList.append([id, cx, cy])\n",
    "                if draw:\n",
    "                    cv2.circle(img, (cx, cy), 5, (255, 0, 255), cv2.FILLED)\n",
    "        return lmList\n",
    "\n",
    "    def normalize_hand(self, img, lmList):\n",
    "        if not lmList:\n",
    "            return None\n",
    "        x_min = min([lm[1] for lm in lmList])\n",
    "        y_min = min([lm[2] for lm in lmList])\n",
    "        x_max = max([lm[1] for lm in lmList])\n",
    "        y_max = max([lm[2] for lm in lmList])\n",
    "\n",
    "        # Ensure coordinates are within the image boundaries\n",
    "        x_min = max(0, x_min)\n",
    "        y_min = max(0, y_min)\n",
    "        x_max = min(img.shape[1], x_max)\n",
    "        y_max = min(img.shape[0], y_max)\n",
    "\n",
    "        if x_max > x_min and y_max > y_min:\n",
    "            hand_img = img[y_min:y_max, x_min:x_max]\n",
    "            standard_size = (200, 200)\n",
    "            normalized_hand_img = cv2.resize(hand_img, standard_size, interpolation=cv2.INTER_AREA)\n",
    "            return normalized_hand_img\n",
    "        else:\n",
    "            return None"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "# Paso 4: Función para recopilar datos de puntos de referencia de manos\n",
    "def collect_data(detector, cap, num_samples_per_label=1000, output_file='hand_landmarks_0_to_5.csv'):\n",
    "    data = []\n",
    "    for label in range(6):  # Etiquetas del 0 al 5\n",
    "        print(f\"Mostrando el número {label}\")\n",
    "        count = 0\n",
    "        while count < num_samples_per_label:\n",
    "            success, img = cap.read()\n",
    "            if not success:\n",
    "                continue\n",
    "            img = detector.find_hands(img)\n",
    "            lmList = detector.find_position(img, draw=False)\n",
    "            normalized_hand = detector.normalize_hand(img, lmList)\n",
    "            if normalized_hand is not None and len(lmList) == 21:\n",
    "                lm_flattened = [coord for lm in lmList for coord in lm[1:]]\n",
    "                data.append(lm_flattened + [label])\n",
    "                count += 1\n",
    "            cv2.imshow(\"Image\", img)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    columns = [f'x{i}' for i in range(21)] + [f'y{i}' for i in range(21)] + ['label']\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "# Recopilar datos\n",
    "if __name__ == \"__main__\":\n",
    "    detector = handDetector(detectionCon=0.75)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    collect_data(detector, cap, num_samples_per_label=1000, output_file='hand_landmarks_0_to_5.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Paso 5: Entrenar el modelo de red neuronal\n",
    "def train_model(data_file='hand_landmarks_0_to_5.csv'):\n",
    "    data = pd.read_csv(data_file)\n",
    "    X = data.drop(['label'], axis=1).values\n",
    "    y = data['label'].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    y = tf.keras.utils.to_categorical(y, num_classes=6)  # 6 clases para números del 0 al 5\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(6, activation='softmax')  # 6 clases para números del 0 al 5\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n",
    "\n",
    "    model.save('hand_gesture_model_0_to_5.h5')\n",
    "    joblib.dump(scaler, 'scaler.pkl')\n",
    "    return model, scaler"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Entrenar el modelo\n",
    "if __name__ == \"__main__\":\n",
    "    model, scaler = train_model(data_file='hand_landmarks_0_to_5.csv')"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
